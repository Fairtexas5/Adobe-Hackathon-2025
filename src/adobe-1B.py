# -*- coding: utf-8 -*-
"""adobe.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rSbftsjc7pg7GfZh0pFNdjSJEOzFgjAA
"""
#install these libraries first
# pip install pandas scikit-learn PyMuPDF sentence-transformers lightgbm numpy

# !pip install doclayout-yolo

# ==============================================================================
#  Standard Library Imports
# ==============================================================================
import json
import os
import joblib
from datetime import datetime

# ==============================================================================
#  Third-party Library Imports
# ==============================================================================
import fitz  # PyMuPDF
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import lightgbm as lgb
import cv2
import torch
from doclayout_yolo import YOLOv10
#1A
class YOLOv10LayoutDetector:
    """
    A wrapper for the YOLOv10 model to handle document layout detection.
    """
    def __init__(self, model_path):
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"YOLO model file not found at {model_path}.")

        print("Loading YOLOv10 model...")
        # Load your actual YOLOv10 model
        self.model = YOLOv10(model_path)
        self.device = "cpu" 
        print("YOLOv10 model loaded successfully.")

    def predict(self, image):
        """
        Runs prediction on a single image and returns formatted results.

        Args:
            image (np.ndarray): The input image in a NumPy array format.

        Returns:
            A list of dictionaries, where each dictionary contains the
            bounding box ('box') and the predicted 'label'.
        """
        # Run the YOLOv10 prediction
        det_res = self.model.predict(
            image,
            imgsz=1024,
            conf=0.2,
            device=self.device
        )

        result = det_res[0]
        boxes = result.boxes

        bbox_list = boxes.xyxy.cpu().numpy()
        class_ids = boxes.cls.cpu().numpy().astype(int)
        id2label = self.model.model.names
        formatted_results = []
        for i in range(len(bbox_list)):
            x1, y1, x2, y2 = map(int, bbox_list[i])
            label = id2label[class_ids[i]]
            formatted_results.append({
                "box": (x1, y1, x2, y2),
                "label": label
            })

        return formatted_results
class HybridPDFExtractor:
    """
    Combines PyMuPDF features with visual layout features from a YOLO model.
    """
    def __init__(self, yolo_model_path, lgbm_model=None):
        # This now instantiates the REAL YOLO detector class
        self.yolo_model = YOLOv10LayoutDetector(yolo_model_path)
        if lgbm_model:
            self.lgbm_model = lgbm_model
        else:
            self.lgbm_model = lgb.LGBMClassifier(random_state=42)

    def _get_layout_feature(self, yolo_boxes, block_bbox):
        """Finds which YOLO layout box a PyMuPDF text block falls into."""
        b_x1, b_y1, b_x2, b_y2 = block_bbox
        b_center_x = (b_x1 + b_x2) / 2
        b_center_y = (b_y1 + b_y2) / 2

        for box_info in yolo_boxes:
            y_x1, y_y1, y_x2, y_y2 = box_info["box"]
            if y_x1 < b_center_x < y_x2 and y_y1 < b_center_y < y_y2:
                return box_info["label"]
        return "unknown"

    def extract_hybrid_features(self, pdf_path):
        doc = fitz.open(pdf_path)
        all_features = []
        for page_num, page in enumerate(doc):
            pix = page.get_pixmap()
            img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)
            if pix.n == 4:
                img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)

            # This now calls the real YOLO model prediction
            yolo_boxes = self.yolo_model.predict(img)

            page_width = page.rect.width
            blocks = page.get_text("dict", flags=11)["blocks"]
            for b in blocks:
                if b.get("lines"):
                    first_span = b["lines"][0]["spans"][0]
                    text = " ".join([s["text"] for l in b["lines"] for s in l["spans"]]).strip()
                    if not text: continue

                    layout_type = self._get_layout_feature(yolo_boxes, b["bbox"])
                    all_features.append({
                        "text": text, "page_num": page_num + 1,
                        "font_size": round(first_span["size"]),
                        "is_bold": "bold" in first_span["font"].lower(),
                        "is_centered": (abs((page_width - (b["bbox"][2] - b["bbox"][0])) / 2 - b["bbox"][0]) < 20),
                        "is_all_caps": text.isupper() and len(text) > 4,
                        "block_length": len(text),
                        "layout_type": layout_type
                    })
        doc.close()
        return pd.DataFrame(all_features)

    def train(self, df_train):
        print("Training LightGBM model on hybrid features...")
        feature_cols = ['font_size', 'is_bold', 'is_centered', 'is_all_caps', 'block_length', 'layout_type']
        df_train['layout_type'] = df_train['layout_type'].astype('category')
        X_train = df_train[feature_cols]
        y_train = df_train['label']
        self.lgbm_model.fit(X_train, y_train)
        print("Training complete.")

    def predict(self, pdf_path):
        features_df = self.extract_hybrid_features(pdf_path)
        if features_df.empty: return {"title": "Unable to process document", "outline_df": pd.DataFrame()}
        feature_cols = ['font_size', 'is_bold', 'is_centered', 'is_all_caps', 'block_length', 'layout_type']
        features_df['layout_type'] = features_df['layout_type'].astype('category')
        X_predict = features_df[feature_cols]
        predictions = self.lgbm_model.predict(X_predict)
        features_df['level'] = predictions
        title = "Default Title"
        title_candidates = features_df[features_df['level'] == 'Title']
        if not title_candidates.empty: title = title_candidates.iloc[0]['text']
        return {"title": title, "outline_df": features_df}

    def save_model(self, filepath="hybrid_model.joblib"):
        joblib.dump(self.lgbm_model, filepath)
        print(f"Hybrid model saved to {filepath}")

    @classmethod
    def load_model(cls, yolo_model_path, lgbm_model_path):
        lgbm_model = joblib.load(lgbm_model_path)
        return cls(yolo_model_path, lgbm_model=lgbm_model)

#1B
class DocumentIntelligence:
    def __init__(self, heading_extractor, embedding_model_name='all-MiniLM-L6-v2'):
        print("Loading models for Round 1B...")
        self.heading_extractor = heading_extractor
        self.embedding_model = SentenceTransformer(embedding_model_name)
        print("Models loaded successfully.")

    def _chunk_document(self, pdf_path):
        structured_output = self.heading_extractor.predict(pdf_path)
        outline_df = structured_output.get("outline_df")
        if outline_df is None or outline_df.empty: return []
        chunks = []
        for i, row in outline_df.iterrows():
            if row['level'] in ['H1', 'H2', 'H3']:
                chunk_content = row['text']
                for j in range(i + 1, len(outline_df)):
                    next_row = outline_df.iloc[j]
                    if next_row['level'] == 'Body':
                        chunk_content += " " + next_row['text']
                    else:
                        break
                chunks.append({
                    "document": os.path.basename(pdf_path),
                    "page_number": row['page_num'],
                    "section_title": row['text'],
                    "content": chunk_content
                })
        return chunks

    def find_relevant_sections(self, pdf_paths, persona, job_to_be_done):
        query = f"As a {persona}, my goal is to {job_to_be_done}."
        query_embedding = self.embedding_model.encode([query])
        all_chunks = []
        for pdf_path in pdf_paths:
            all_chunks.extend(self._chunk_document(pdf_path))
        if not all_chunks: return {"error": "No content could be extracted."}
        chunk_contents = [chunk['content'] for chunk in all_chunks]
        chunk_embeddings = self.embedding_model.encode(chunk_contents)
        similarities = cosine_similarity(query_embedding, chunk_embeddings)[0]
        for i, chunk in enumerate(all_chunks):
            chunk['relevance_score'] = similarities[i]
        sorted_chunks = sorted(all_chunks, key=lambda x: x['relevance_score'], reverse=True)
        output = {
            "metadata": {"input_documents": [os.path.basename(p) for p in pdf_paths], "persona": persona, "job_to_be_done": job_to_be_done, "processing_timestamp": datetime.now().isoformat()},
            "extracted_sections": [],
            "subsection_analysis": []
        }
        for i, chunk in enumerate(sorted_chunks[:5]):
            output["extracted_sections"].append({"document": chunk['document'], "section_title": chunk['section_title'], "importance_rank": i + 1, "page_number": chunk['page_number']})
            output["subsection_analysis"].append({"document": chunk['document'], "refined_text": chunk['content'], "page_number": chunk['page_number']})
        return output

if __name__ == '__main__':
    YOLO_MODEL_PATH = "/content/doclayout_layout_model.pt"
    LGBM_MODEL_PATH = "/content/hybrid_lgbm_model.joblib"

    print("--- STEP 1: TRAINING THE HYBRID 1A MODEL ---")
    try:
        real_data_1 = pd.read_csv("/content/labeled_data.csv")
     
        master_labeled_df = real_data_1
    except FileNotFoundError:
        print("Warning: Labeled CSV files not found. Skipping training.")
        master_labeled_df = None

    if master_labeled_df is not None:
        if 'layout_type' not in master_labeled_df.columns:
            master_labeled_df['layout_type'] = 'text'

        hybrid_extractor_for_training = HybridPDFExtractor(yolo_model_path=YOLO_MODEL_PATH)
        hybrid_extractor_for_training.train(master_labeled_df)
        hybrid_extractor_for_training.save_model(LGBM_MODEL_PATH)

    print("\n--- STEP 2: RUNNING THE FULL 1B ANALYSIS ---")
    if not os.path.exists(LGBM_MODEL_PATH):
        print("Error: Trained model not found. Please run the training step first.")
    else:
        trained_hybrid_extractor = HybridPDFExtractor.load_model(yolo_model_path=YOLO_MODEL_PATH, lgbm_model_path=LGBM_MODEL_PATH)
        intelligence_system = DocumentIntelligence(heading_extractor=trained_hybrid_extractor)
        PDF_DOCUMENTS_DIR = "travel_docs/"
        if not os.path.exists(PDF_DOCUMENTS_DIR): os.makedirs(PDF_DOCUMENTS_DIR)
        document_names = [f for f in os.listdir(PDF_DOCUMENTS_DIR) if f.endswith('.pdf')]
        PDF_FILES_PATHS = [os.path.join(PDF_DOCUMENTS_DIR, name) for name in document_names]

        if not PDF_FILES_PATHS:
            print("\nWarning: No PDFs found in 'travel_docs/'. The 1B analysis will not produce results.")
        else:
            PERSONA = "Travel Planner"
            JOB_TO_BE_DONE = "Plan a trip of 4 days for a group of 10 college friends"
            final_output = intelligence_system.find_relevant_sections(pdf_paths=PDF_FILES_PATHS, persona=PERSONA, job_to_be_done=JOB_TO_BE_DONE)
            print("\n--- FINAL 1B OUTPUT ---")
            print(json.dumps(final_output, indent=4))